{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# ğŸ”‹ ë°°í„°ë¦¬ ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„ í†µí•© ë…¸íŠ¸ë¶\n",
    "\n",
    "## ğŸ“‹ ëª©ì°¨\n",
    "1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ\n",
    "2. ì›ì‹œ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "3. ì‹œê³„ì—´ ìˆœì„œ ì •ë ¬\n",
    "4. ì±„ë„ë³„ ë°ì´í„° ë¶„ë¦¬\n",
    "5. ëˆ„ì ì‹œê°„ ê¸°ë°˜ ì‹œê°í™”\n",
    "6. ì‚¬ì´í´ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "7. í†µê³„ ìš”ì•½ ë° ë¦¬í¬íŠ¸\n",
    "\n",
    "## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°\n",
    "```\n",
    "DataPreprocess_250826/\n",
    "â”œâ”€â”€ src/                    # ì†ŒìŠ¤ì½”ë“œ\n",
    "â”œâ”€â”€ outputs/               # ì¶œë ¥ í´ë”\n",
    "â”‚   â””â”€â”€ run_YYYYMMDD_HHMMSS/\n",
    "â”‚       â”œâ”€â”€ channels/      # ì±„ë„ë³„ ë¶„ë¦¬ ë°ì´í„°\n",
    "â”‚       â”œâ”€â”€ plots/         # ì‹œê°í™” íŒŒì¼\n",
    "â”‚       â”œâ”€â”€ processed/     # ì „ì²˜ë¦¬ëœ ì›ë³¸ ë°ì´í„°\n",
    "â”‚       â””â”€â”€ logs/          # ë¡œê·¸ íŒŒì¼\n",
    "â””â”€â”€ Rawdata/               # ì›ì‹œ ë°ì´í„°\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# seaborn ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "project_root = Path().absolute().parent  # src í´ë”ì˜ ìƒìœ„ í´ë”\n",
    "sys.path.append(str(project_root / 'src'))\n",
    "\n",
    "print(\"[í™˜ê²½ì„¤ì •] ì™„ë£Œ\")\n",
    "print(f\"[í”„ë¡œì íŠ¸ ê²½ë¡œ] {project_root}\")\n",
    "print(f\"[Python ë²„ì „] {sys.version}\")\n",
    "print(f\"[Pandas ë²„ì „] {pd.__version__}\")\n",
    "print(f\"[Numpy ë²„ì „] {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 2. ì›ì‹œ ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°°í„°ë¦¬ í”„ë¡œì„¸ì„œ ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "try:\n",
    "    from improved_battery_processor import BatteryDataProcessor, Config\n",
    "    print(\"[OK] ë°°í„°ë¦¬ í”„ë¡œì„¸ì„œ ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ\")\n",
    "except ImportError as e:\n",
    "    print(f\"[ì˜¤ë¥˜] ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"src/ í´ë”ì— improved_battery_processor.pyê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ì‹œ ë°ì´í„° ì²˜ë¦¬\n",
    "raw_data_path = project_root / 'Rawdata' / '250207_250307_3_ê¹€ë™ì§„_1689mAh_ATL Q7M Inner 2C ìƒì˜¨ìˆ˜ëª… 1-100cyc'\n",
    "\n",
    "if raw_data_path.exists():\n",
    "    print(f\"[ë°ì´í„° ë°œê²¬] {raw_data_path.name}\")\n",
    "    print(\"[ì²˜ë¦¬ ì‹œì‘] ë°°í„°ë¦¬ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "    \n",
    "    # ì„¤ì •\n",
    "    config = Config(\n",
    "        MAX_FILES_PER_CHANNEL=500,\n",
    "        PARALLEL_PROCESSING=True,\n",
    "        MAX_WORKERS=2,\n",
    "        LOG_LEVEL='INFO'\n",
    "    )\n",
    "    \n",
    "    processor = BatteryDataProcessor(config)\n",
    "    \n",
    "    # ë°ì´í„° ì²˜ë¦¬ ì‹¤í–‰\n",
    "    try:\n",
    "        results = processor.process_paths([raw_data_path])\n",
    "        \n",
    "        if results and results[0].channel_data:\n",
    "            result = results[0]\n",
    "            print(\"\\n[ì²˜ë¦¬ ì™„ë£Œ] ì„±ê³µ!\")\n",
    "            print(f\"  - ë°ì´í„° í¬ë§·: {result.data_format}\")\n",
    "            print(f\"  - ì±„ë„ ìˆ˜: {len(result.channel_data)}ê°œ\")\n",
    "            print(f\"  - CSV íŒŒì¼: {result.csv_file}\")\n",
    "            print(f\"  - í”Œë¡¯ íŒŒì¼: {result.plot_file}\")\n",
    "            \n",
    "            # ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥\n",
    "            processed_result = result\n",
    "            channel_data_dict = result.channel_data\n",
    "        else:\n",
    "            print(\"[ì˜¤ë¥˜] ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[ì˜¤ë¥˜] ì²˜ë¦¬ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "        import traceback\n",
    "        print(traceback.format_exc())\n",
    "else:\n",
    "    print(f\"[ì˜¤ë¥˜] ì›ì‹œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {raw_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. ì‹œê³„ì—´ ìˆœì„œ ì •ë ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_timeseries_data(df):\n",
    "    \"\"\"\n",
    "    ì‹œê³„ì—´ ë°ì´í„°ë¥¼ Date + Time ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "    \"\"\"\n",
    "    if 'Date' in df.columns and 'Time' in df.columns:\n",
    "        print(\"[ì •ë ¬] Date + Time ê¸°ì¤€ ì •ë ¬ ì¤‘...\")\n",
    "        \n",
    "        # DateTime ìƒì„±\n",
    "        df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        \n",
    "        # ì •ë ¬ ì „ ìƒíƒœ\n",
    "        is_sorted_before = df['DateTime'].is_monotonic_increasing\n",
    "        print(f\"  ì •ë ¬ ì „: {'ì´ë¯¸ ì •ë ¬ë¨' if is_sorted_before else 'ì •ë ¬ í•„ìš”'}\")\n",
    "        \n",
    "        # ì •ë ¬\n",
    "        df_sorted = df.sort_values('DateTime').reset_index(drop=True)\n",
    "        \n",
    "        # ì •ë ¬ í›„ ìƒíƒœ\n",
    "        is_sorted_after = df_sorted['DateTime'].is_monotonic_increasing\n",
    "        print(f\"  ì •ë ¬ í›„: {'ì •ë ¬ ì™„ë£Œ' if is_sorted_after else 'ì •ë ¬ ì‹¤íŒ¨'}\")\n",
    "        \n",
    "        # DateTime ì»¬ëŸ¼ ì œê±° (ì„ì‹œ ì»¬ëŸ¼)\n",
    "        df_sorted = df_sorted.drop('DateTime', axis=1)\n",
    "        \n",
    "        return df_sorted\n",
    "    else:\n",
    "        print(\"[ê²½ê³ ] Date ë˜ëŠ” Time ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return df\n",
    "\n",
    "# ì±„ë„ë³„ ë°ì´í„° ì •ë ¬\n",
    "if 'channel_data_dict' in locals():\n",
    "    print(\"\\n[ì‹œê³„ì—´ ì •ë ¬] ì±„ë„ë³„ ë°ì´í„° ì •ë ¬ ì‹œì‘\")\n",
    "    \n",
    "    sorted_channel_data = {}\n",
    "    \n",
    "    for channel, df in channel_data_dict.items():\n",
    "        print(f\"\\n{channel} ì •ë ¬ ì¤‘...\")\n",
    "        df_sorted = sort_timeseries_data(df)\n",
    "        sorted_channel_data[channel] = df_sorted\n",
    "        print(f\"  ë°ì´í„° í¬ê¸°: {len(df_sorted):,} í–‰\")\n",
    "        \n",
    "        # ì‹œê°„ ë²”ìœ„ í™•ì¸\n",
    "        if 'Date' in df_sorted.columns:\n",
    "            print(f\"  ê¸°ê°„: {df_sorted['Date'].min()} ~ {df_sorted['Date'].max()}\")\n",
    "    \n",
    "    channel_data_dict = sorted_channel_data\n",
    "    print(\"\\n[ì •ë ¬ ì™„ë£Œ] ëª¨ë“  ì±„ë„ ì‹œê³„ì—´ ì •ë ¬ ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"[ê±´ë„ˆë›°ê¸°] ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. ì±„ë„ë³„ ë°ì´í„° ë¶„ë¦¬ ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ êµ¬ì¡° ê´€ë¦¬\n",
    "try:\n",
    "    from setup_project_structure import ProjectStructureManager\n",
    "    print(\"[OK] í”„ë¡œì íŠ¸ êµ¬ì¡° ê´€ë¦¬ ëª¨ë“ˆ ë¡œë“œ\")\n",
    "except ImportError:\n",
    "    print(\"[ê²½ê³ ] setup_project_structure ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = project_root / 'outputs' / f'run_{timestamp}'\n",
    "channels_dir = output_dir / 'channels'\n",
    "plots_dir = output_dir / 'plots'\n",
    "processed_dir = output_dir / 'processed'\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for dir_path in [channels_dir, plots_dir, processed_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"[ë””ë ‰í† ë¦¬ ìƒì„±] {output_dir}\")\n",
    "\n",
    "# ì±„ë„ë³„ ë°ì´í„° ì €ì¥\n",
    "if 'channel_data_dict' in locals():\n",
    "    print(\"\\n[ì±„ë„ë³„ ì €ì¥] ë°ì´í„° íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    saved_files = {}\n",
    "    \n",
    "    for channel, df in channel_data_dict.items():\n",
    "        # íŒŒì¼ëª… ìƒì„±\n",
    "        base_name = '250207_250307_3_ê¹€ë™ì§„_1689mAh_ATL_Q7M_Inner_2C_ìƒì˜¨ìˆ˜ëª…'\n",
    "        channel_filename = f\"{base_name}_{channel}.csv\"\n",
    "        channel_path = channels_dir / channel_filename\n",
    "        \n",
    "        # CSV ì €ì¥\n",
    "        df.to_csv(channel_path, index=False, encoding='utf-8-sig')\n",
    "        saved_files[channel] = channel_path\n",
    "        \n",
    "        file_size = channel_path.stat().st_size / (1024*1024)  # MB\n",
    "        print(f\"  {channel}: {channel_filename} ({file_size:.1f}MB)\")\n",
    "    \n",
    "    print(f\"\\n[ì €ì¥ ì™„ë£Œ] {len(saved_files)}ê°œ ì±„ë„ íŒŒì¼ ìƒì„±\")\n",
    "    \n",
    "    # ì „ì—­ ë³€ìˆ˜ë¡œ ì €ì¥\n",
    "    channel_files = saved_files\n",
    "else:\n",
    "    print(\"[ê±´ë„ˆë›°ê¸°] ì €ì¥í•  ì±„ë„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. ëˆ„ì ì‹œê°„ ê¸°ë°˜ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cumulative_time(df):\n",
    "    \"\"\"\n",
    "    ëˆ„ì ì‹œê°„ ì»¬ëŸ¼ ì¶”ê°€\n",
    "    \"\"\"\n",
    "    if 'Date' in df.columns and 'Time' in df.columns:\n",
    "        df['DateTime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])\n",
    "        start_time = df['DateTime'].min()\n",
    "        df['Cumulative_Time_Hours'] = (df['DateTime'] - start_time).dt.total_seconds() / 3600.0\n",
    "    elif 'Time_Sec' in df.columns:\n",
    "        min_time = df['Time_Sec'].min()\n",
    "        df['Cumulative_Time_Hours'] = (df['Time_Sec'] - min_time) / 3600.0\n",
    "    else:\n",
    "        df['Cumulative_Time_Hours'] = np.arange(len(df)) / 3600.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ëˆ„ì ì‹œê°„ ì¶”ê°€ ë° ì‹œê°í™”\n",
    "if 'channel_data_dict' in locals():\n",
    "    print(\"[ëˆ„ì ì‹œê°„] ì»¬ëŸ¼ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    # ëˆ„ì ì‹œê°„ ì¶”ê°€\n",
    "    for channel, df in channel_data_dict.items():\n",
    "        df = add_cumulative_time(df)\n",
    "        channel_data_dict[channel] = df\n",
    "        max_hours = df['Cumulative_Time_Hours'].max()\n",
    "        print(f\"  {channel}: ëˆ„ì ì‹œê°„ {max_hours:.1f} ì‹œê°„ ({max_hours/24:.1f} ì¼)\")\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    print(\"\\n[ì‹œê°í™”] ëˆ„ì ì‹œê°„ ê¸°ë°˜ í”Œë¡¯ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('ë°°í„°ë¦¬ ì„±ëŠ¥ ë¶„ì„ - ëˆ„ì ì‹œê°„ ê¸°ì¤€', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "    \n",
    "    for i, (channel, df) in enumerate(channel_data_dict.items()):\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        # ë°ì´í„° ìƒ˜í”Œë§ (ì„±ëŠ¥ì„ ìœ„í•´)\n",
    "        sample_rate = max(1, len(df) // 5000)\n",
    "        df_sample = df.iloc[::sample_rate].copy()\n",
    "        \n",
    "        # 1. ì „ì••\n",
    "        axes[0, 0].plot(df_sample['Cumulative_Time_Hours'], df_sample['Voltage_V'],\n",
    "                       color=color, alpha=0.8, linewidth=1.5, label=channel)\n",
    "        \n",
    "        # 2. ì „ë¥˜\n",
    "        axes[0, 1].plot(df_sample['Cumulative_Time_Hours'], df_sample['Current_A'],\n",
    "                       color=color, alpha=0.8, linewidth=1.5, label=channel)\n",
    "        \n",
    "        # 3. ìš©ëŸ‰\n",
    "        if 'Capacity_Ah' in df_sample.columns:\n",
    "            axes[1, 0].plot(df_sample['Cumulative_Time_Hours'], df_sample['Capacity_Ah'],\n",
    "                           color=color, alpha=0.8, linewidth=1.5, label=channel)\n",
    "        \n",
    "        # 4. SOC\n",
    "        if 'SOC_%' in df_sample.columns:\n",
    "            axes[1, 1].plot(df_sample['Cumulative_Time_Hours'], df_sample['SOC_%'],\n",
    "                           color=color, alpha=0.8, linewidth=1.5, label=channel)\n",
    "    \n",
    "    # ì¶• ì„¤ì •\n",
    "    titles = ['ì „ì•• vs ëˆ„ì ì‹œê°„', 'ì „ë¥˜ vs ëˆ„ì ì‹œê°„', 'ìš©ëŸ‰ vs ëˆ„ì ì‹œê°„', 'SOC vs ëˆ„ì ì‹œê°„']\n",
    "    ylabels = ['ì „ì•• (V)', 'ì „ë¥˜ (A)', 'ìš©ëŸ‰ (Ah)', 'SOC (%)']\n",
    "    \n",
    "    for ax, title, ylabel in zip(axes.flat, titles, ylabels):\n",
    "        ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "        ax.set_xlabel('ëˆ„ì ì‹œê°„ (hours)', fontsize=10)\n",
    "        ax.set_ylabel(ylabel, fontsize=10)\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ì €ì¥\n",
    "    plot_path = plots_dir / 'cumulative_time_analysis.png'\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"[ì €ì¥] {plot_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"[ê±´ë„ˆë›°ê¸°] ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. ì‚¬ì´í´ë³„ ì„±ëŠ¥ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì´í´ë³„ ìš”ì•½ í†µê³„ ê³„ì‚°\n",
    "def calculate_cycle_summary(df):\n",
    "    \"\"\"\n",
    "    ì‚¬ì´í´ë³„ ìš”ì•½ í†µê³„ ê³„ì‚°\n",
    "    \"\"\"\n",
    "    if 'TotalCycle' not in df.columns:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    summary_list = []\n",
    "    \n",
    "    for cycle in df['TotalCycle'].unique():\n",
    "        cycle_data = df[df['TotalCycle'] == cycle]\n",
    "        \n",
    "        if len(cycle_data) < 10:\n",
    "            continue\n",
    "        \n",
    "        summary = {\n",
    "            'Cycle': int(cycle),\n",
    "            'Data_Points': len(cycle_data),\n",
    "            'Duration_Hours': cycle_data['Cumulative_Time_Hours'].max() - cycle_data['Cumulative_Time_Hours'].min() if 'Cumulative_Time_Hours' in cycle_data.columns else 0,\n",
    "            'Voltage_Min': cycle_data['Voltage_V'].min(),\n",
    "            'Voltage_Max': cycle_data['Voltage_V'].max(),\n",
    "            'Voltage_Avg': cycle_data['Voltage_V'].mean(),\n",
    "            'Current_Min': cycle_data['Current_A'].min() if 'Current_A' in cycle_data.columns else 0,\n",
    "            'Current_Max': cycle_data['Current_A'].max() if 'Current_A' in cycle_data.columns else 0,\n",
    "            'Capacity_Max': cycle_data['Capacity_Ah'].max() if 'Capacity_Ah' in cycle_data.columns else 0,\n",
    "            'Temperature_Avg': cycle_data['Temperature_C'].mean() if 'Temperature_C' in cycle_data.columns else 0\n",
    "        }\n",
    "        \n",
    "        summary_list.append(summary)\n",
    "    \n",
    "    return pd.DataFrame(summary_list)\n",
    "\n",
    "# ì±„ë„ë³„ ì‚¬ì´í´ ìš”ì•½\n",
    "if 'channel_data_dict' in locals():\n",
    "    print(\"[ì‚¬ì´í´ ë¶„ì„] ì±„ë„ë³„ ì‚¬ì´í´ ìš”ì•½ ê³„ì‚° ì¤‘...\")\n",
    "    \n",
    "    cycle_summaries = {}\n",
    "    \n",
    "    for channel, df in channel_data_dict.items():\n",
    "        summary_df = calculate_cycle_summary(df)\n",
    "        cycle_summaries[channel] = summary_df\n",
    "        print(f\"\\n{channel} ì‚¬ì´í´ ìš”ì•½:\")\n",
    "        print(f\"  ì´ ì‚¬ì´í´ ìˆ˜: {len(summary_df)}\")\n",
    "        \n",
    "        if not summary_df.empty:\n",
    "            print(f\"  í‰ê·  ìš©ëŸ‰: {summary_df['Capacity_Max'].mean():.3f} Ah\")\n",
    "            print(f\"  í‰ê·  ì „ì••: {summary_df['Voltage_Avg'].mean():.3f} V\")\n",
    "            print(f\"  í‰ê·  ì§€ì†ì‹œê°„: {summary_df['Duration_Hours'].mean():.2f} ì‹œê°„\")\n",
    "    \n",
    "    # ì‚¬ì´í´ë³„ ìš©ëŸ‰ ë³€í™” ì‹œê°í™”\n",
    "    if cycle_summaries:\n",
    "        print(\"\\n[ì‹œê°í™”] ì‚¬ì´í´ë³„ ìš©ëŸ‰ ë³€í™”\")\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        for channel, summary_df in cycle_summaries.items():\n",
    "            if 'Capacity_Max' in summary_df.columns:\n",
    "                ax.plot(summary_df['Cycle'], summary_df['Capacity_Max'],\n",
    "                       'o-', label=channel, markersize=4, linewidth=1.5)\n",
    "        \n",
    "        ax.set_title('ì‚¬ì´í´ë³„ ìµœëŒ€ ìš©ëŸ‰ ë³€í™”', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('ì‚¬ì´í´', fontsize=12)\n",
    "        ax.set_ylabel('ìµœëŒ€ ìš©ëŸ‰ (Ah)', fontsize=12)\n",
    "        ax.legend(loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # ì €ì¥\n",
    "        plot_path = plots_dir / 'cycle_capacity_trend.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"[ì €ì¥] {plot_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"[ê±´ë„ˆë›°ê¸°] ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. í†µê³„ ìš”ì•½ ë° ë¦¬í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ í†µê³„ ìš”ì•½\n",
    "def generate_summary_report(channel_data_dict, cycle_summaries, output_dir):\n",
    "    \"\"\"\n",
    "    í†µê³„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±\n",
    "    \"\"\"\n",
    "    report_lines = []\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    report_lines.append(\"ë°°í„°ë¦¬ ë°ì´í„° ë¶„ì„ ë¦¬í¬íŠ¸\")\n",
    "    report_lines.append(f\"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    report_lines.append(\"\")\n",
    "    \n",
    "    # ì±„ë„ë³„ ìš”ì•½\n",
    "    report_lines.append(\"1. ì±„ë„ë³„ ë°ì´í„° ìš”ì•½\")\n",
    "    report_lines.append(\"-\" * 40)\n",
    "    \n",
    "    for channel, df in channel_data_dict.items():\n",
    "        report_lines.append(f\"\\n{channel}:\")\n",
    "        report_lines.append(f\"  - ë°ì´í„° í¬ì¸íŠ¸: {len(df):,}ê°œ\")\n",
    "        \n",
    "        if 'Date' in df.columns:\n",
    "            report_lines.append(f\"  - ì¸¡ì • ê¸°ê°„: {df['Date'].min()} ~ {df['Date'].max()}\")\n",
    "        \n",
    "        if 'Voltage_V' in df.columns:\n",
    "            report_lines.append(f\"  - ì „ì•• ë²”ìœ„: {df['Voltage_V'].min():.3f} ~ {df['Voltage_V'].max():.3f} V\")\n",
    "            report_lines.append(f\"  - í‰ê·  ì „ì••: {df['Voltage_V'].mean():.3f} Â± {df['Voltage_V'].std():.3f} V\")\n",
    "        \n",
    "        if 'Current_A' in df.columns:\n",
    "            report_lines.append(f\"  - ì „ë¥˜ ë²”ìœ„: {df['Current_A'].min():.3f} ~ {df['Current_A'].max():.3f} A\")\n",
    "        \n",
    "        if 'Capacity_Ah' in df.columns:\n",
    "            report_lines.append(f\"  - ìµœëŒ€ ìš©ëŸ‰: {df['Capacity_Ah'].max():.3f} Ah\")\n",
    "        \n",
    "        if 'Cumulative_Time_Hours' in df.columns:\n",
    "            total_hours = df['Cumulative_Time_Hours'].max()\n",
    "            report_lines.append(f\"  - ì´ ì¸¡ì • ì‹œê°„: {total_hours:.1f} ì‹œê°„ ({total_hours/24:.1f} ì¼)\")\n",
    "    \n",
    "    # ì‚¬ì´í´ ìš”ì•½\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"2. ì‚¬ì´í´ ë¶„ì„ ìš”ì•½\")\n",
    "    report_lines.append(\"-\" * 40)\n",
    "    \n",
    "    for channel, summary_df in cycle_summaries.items():\n",
    "        if not summary_df.empty:\n",
    "            report_lines.append(f\"\\n{channel}:\")\n",
    "            report_lines.append(f\"  - ì´ ì‚¬ì´í´ ìˆ˜: {len(summary_df)}\")\n",
    "            report_lines.append(f\"  - í‰ê·  ì‚¬ì´í´ ì‹œê°„: {summary_df['Duration_Hours'].mean():.2f} ì‹œê°„\")\n",
    "            report_lines.append(f\"  - ì´ˆê¸° ìš©ëŸ‰ (1-10 ì‚¬ì´í´): {summary_df.head(10)['Capacity_Max'].mean():.3f} Ah\")\n",
    "            report_lines.append(f\"  - ìµœê·¼ ìš©ëŸ‰ (ë§ˆì§€ë§‰ 10 ì‚¬ì´í´): {summary_df.tail(10)['Capacity_Max'].mean():.3f} Ah\")\n",
    "            \n",
    "            # ìš©ëŸ‰ ê°ì†Œìœ¨ ê³„ì‚°\n",
    "            if len(summary_df) > 10:\n",
    "                initial_cap = summary_df.head(10)['Capacity_Max'].mean()\n",
    "                final_cap = summary_df.tail(10)['Capacity_Max'].mean()\n",
    "                retention = (final_cap / initial_cap * 100) if initial_cap > 0 else 0\n",
    "                report_lines.append(f\"  - ìš©ëŸ‰ ìœ ì§€ìœ¨: {retention:.1f}%\")\n",
    "    \n",
    "    # íŒŒì¼ ì •ë³´\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"3. ìƒì„±ëœ íŒŒì¼\")\n",
    "    report_lines.append(\"-\" * 40)\n",
    "    report_lines.append(f\"  - ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}\")\n",
    "    report_lines.append(f\"  - ì±„ë„ ë°ì´í„°: {output_dir}/channels/\")\n",
    "    report_lines.append(f\"  - ì‹œê°í™” íŒŒì¼: {output_dir}/plots/\")\n",
    "    report_lines.append(f\"  - ì²˜ë¦¬ëœ ì›ë³¸: {output_dir}/processed/\")\n",
    "    \n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"=\" * 80)\n",
    "    report_lines.append(\"ë¦¬í¬íŠ¸ ë\")\n",
    "    \n",
    "    return \"\\n\".join(report_lines)\n",
    "\n",
    "# ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥\n",
    "if 'channel_data_dict' in locals() and 'cycle_summaries' in locals():\n",
    "    print(\"[ë¦¬í¬íŠ¸] í†µê³„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...\")\n",
    "    \n",
    "    report_content = generate_summary_report(channel_data_dict, cycle_summaries, output_dir)\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ ì¶œë ¥\n",
    "    print(\"\\n\" + report_content)\n",
    "    \n",
    "    # íŒŒì¼ë¡œ ì €ì¥\n",
    "    report_path = output_dir / 'analysis_report.txt'\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(report_content)\n",
    "    \n",
    "    print(f\"\\n[ì €ì¥] ë¦¬í¬íŠ¸ íŒŒì¼: {report_path}\")\n",
    "else:\n",
    "    print(\"[ê±´ë„ˆë›°ê¸°] ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. ìµœì¢… ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í™•ì¸\n",
    "print(\"[ìµœì¢… í™•ì¸] ìƒì„±ëœ íŒŒì¼ ëª©ë¡\\n\")\n",
    "\n",
    "if output_dir.exists():\n",
    "    # ì±„ë„ íŒŒì¼\n",
    "    channel_files = list(channels_dir.glob('*.csv'))\n",
    "    print(f\"ğŸ“ ì±„ë„ ë°ì´í„° ({len(channel_files)}ê°œ):\")\n",
    "    for file in channel_files:\n",
    "        size_mb = file.stat().st_size / (1024*1024)\n",
    "        print(f\"  - {file.name} ({size_mb:.1f}MB)\")\n",
    "    \n",
    "    # í”Œë¡¯ íŒŒì¼\n",
    "    plot_files = list(plots_dir.glob('*.png'))\n",
    "    print(f\"\\nğŸ“Š ì‹œê°í™” íŒŒì¼ ({len(plot_files)}ê°œ):\")\n",
    "    for file in plot_files:\n",
    "        size_kb = file.stat().st_size / 1024\n",
    "        print(f\"  - {file.name} ({size_kb:.1f}KB)\")\n",
    "    \n",
    "    # ë¦¬í¬íŠ¸ íŒŒì¼\n",
    "    report_files = list(output_dir.glob('*.txt'))\n",
    "    print(f\"\\nğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼ ({len(report_files)}ê°œ):\")\n",
    "    for file in report_files:\n",
    "        print(f\"  - {file.name}\")\n",
    "    \n",
    "    print(f\"\\nâœ… ëª¨ë“  íŒŒì¼ì´ ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "    print(f\"   {output_dir}\")\n",
    "else:\n",
    "    print(\"âŒ ì¶œë ¥ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## ğŸ¯ ì™„ë£Œ!\n",
    "\n",
    "### âœ… ìˆ˜í–‰ëœ ì‘ì—…\n",
    "1. **ì›ì‹œ ë°ì´í„° ì „ì²˜ë¦¬**: TOYO í¬ë§· ìë™ ê°ì§€ ë° ì²˜ë¦¬\n",
    "2. **ì‹œê³„ì—´ ì •ë ¬**: Date + Time ê¸°ì¤€ ì˜¬ë°”ë¥¸ ìˆœì„œ ì •ë ¬\n",
    "3. **ì±„ë„ë³„ ë¶„ë¦¬**: Ch30, Ch31 ê°œë³„ CSV íŒŒì¼ ìƒì„±\n",
    "4. **ëˆ„ì ì‹œê°„ ë¶„ì„**: ì „ì²´ í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì—°ì† ì‹œê°í™”\n",
    "5. **ì‚¬ì´í´ ì„±ëŠ¥**: ì‚¬ì´í´ë³„ ìš©ëŸ‰ ë³€í™” ì¶”ì \n",
    "6. **í†µê³„ ë¦¬í¬íŠ¸**: ì¢…í•© ë¶„ì„ ê²°ê³¼ ë¬¸ì„œí™”\n",
    "\n",
    "### ğŸ“ ì¶œë ¥ êµ¬ì¡°\n",
    "```\n",
    "outputs/run_YYYYMMDD_HHMMSS/\n",
    "â”œâ”€â”€ channels/              # ì±„ë„ë³„ CSV ë°ì´í„°\n",
    "â”‚   â”œâ”€â”€ *_Ch30.csv\n",
    "â”‚   â””â”€â”€ *_Ch31.csv\n",
    "â”œâ”€â”€ plots/                 # ì‹œê°í™” ê²°ê³¼\n",
    "â”‚   â”œâ”€â”€ cumulative_time_analysis.png\n",
    "â”‚   â””â”€â”€ cycle_capacity_trend.png\n",
    "â”œâ”€â”€ processed/             # ì›ë³¸ ì²˜ë¦¬ ë°ì´í„°\n",
    "â””â”€â”€ analysis_report.txt   # ë¶„ì„ ë¦¬í¬íŠ¸\n",
    "```\n",
    "\n",
    "### ğŸš€ ë‹¤ìŒ ë‹¨ê³„\n",
    "- ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ì´ìš©í•œ ìˆ˜ëª… ì˜ˆì¸¡\n",
    "- ì´ìƒ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ì ìš©\n",
    "- ë‹¤ì¤‘ í…ŒìŠ¤íŠ¸ ë¹„êµ ë¶„ì„\n",
    "- ìë™í™”ëœ ë¦¬í¬íŠ¸ ìƒì„± ì‹œìŠ¤í…œ êµ¬ì¶•"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}